{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10125911,"sourceType":"datasetVersion","datasetId":6171522}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation","metadata":{}},{"cell_type":"markdown","source":"## Install dependecies","metadata":{}},{"cell_type":"code","source":"update = False\n\nfrom os import path\n\n\n%cd /kaggle/working\n!git clone https://github.com/comfyanonymous/ComfyUI.git\n%cd ComfyUI\nif update:\n    get_ipython().system('git pull')\n!pip install -r requirements.txt\n\ncheckpoints =  '/kaggle/working/ComfyUI/models/checkpoints'\nlink_path = checkpoints + '/temp-models'\ntemp_models = '/kaggle/temp/temp-models'\n\n!mkdir /kaggle/temp\n!mkdir $temp_models\n\nif not path.exists(link_path):\n    get_ipython().system(f'ln -s {temp_models} {checkpoints}')\n\n!mamba install openssh -y\n# !micromamba install openssh -y\n\n\n# Install the node manager\nupdate_manager = False\n%cd /kaggle/working/ComfyUI/custom_nodes\n!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n%cd ComfyUI-Manager\nif update_manager:\n    get_ipython().system('git pull')\n!pip install -r requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics==8.3.45\n!pip install comfy-cli","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!echo \"yes\" | comfy node update all\n!echo \"yes\" | comfy node install-deps \\\n--workflow=\"/kaggle/input/virtual-tryon-workflow/Virtual_TryOn.json\"\n!echo \"yes\" | comfy node update all\n!echo \"yes\" | comfy set-default \"/kaggle/working/ComfyUI\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Yolo-Cropper\n%cd /kaggle/working/ComfyUI/custom_nodes\n!git clone https://github.com/HongQuan1812/ComfyUI-Yolo-Cropper.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:36:25.480469Z","iopub.execute_input":"2024-12-25T08:36:25.480806Z","iopub.status.idle":"2024-12-25T08:36:28.387849Z","shell.execute_reply.started":"2024-12-25T08:36:25.480771Z","shell.execute_reply":"2024-12-25T08:36:28.386807Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ComfyUI/custom_nodes\nCloning into 'ComfyUI-Yolo-Cropper'...\nremote: Enumerating objects: 38, done.\u001b[K\nremote: Counting objects: 100% (38/38), done.\u001b[K\nremote: Compressing objects: 100% (35/35), done.\u001b[K\nremote: Total 38 (delta 15), reused 12 (delta 2), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (38/38), 2.24 MiB | 38.86 MiB/s, done.\nResolving deltas: 100% (15/15), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"---\n# Model Management","metadata":{}},{"cell_type":"markdown","source":"## Install a model\n\nCopy the model URL to the model_url field. Make sure the model can be accessed publicly, without being signed into a website.","metadata":{}},{"cell_type":"code","source":"def install_civitai_model(api_key, model_version_id, \n                          place=None, model_name=None, \n                          type=None, format=None, size=None, fp=None):\n    \n    url_base = f'https://civitai.com/api/download/models/{model_version_id}'\n    model_url = url_base\n\n    if any([type, format, size, fp]):\n        model_url += '?'\n    \n        # Build the query parameters\n        conditions = []\n        if type is not None:\n            conditions.append(f\"type={type}\")\n        if format is not None:\n            conditions.append(f\"format={format}\")\n        if size is not None:\n            conditions.append(f\"size={size}\")\n        if fp is not None:\n            conditions.append(f\"fp={fp}\")\n    \n        # Join the parameters with '&'\n        query_string = \"&\".join(conditions)\n\n        model_url += query_string\n        model_url += f\"&token={api_key}\"\n        \n    else:\n        model_url += f\"?token={api_key}\"\n        \n\n    if model_name is not None:\n        command = f'wget -O \"{model_name}\" \"{model_url}\"'\n    else:\n        command = f'wget \"{model_url}\"'\n    \n    # print(model_url)\n    try: \n        %cd $place\n        get_ipython().system(command)\n        print(\"-----------------------------------\")\n        print(\"| Downloading process is complete |\")\n        print(\"-----------------------------------\")\n    except Exception as err:\n        print(f\"An error occurred: {err}\")\n\napi_key = \"398343858e0078ffee8f0967b3531105\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndef ensure_directory_exists(directory_path):\n    \"\"\"\n    Ensures that the specified directory exists. \n    If it doesn't exist, it creates the directory.\n\n    Args:\n        directory_path (str): The path of the directory to check or create.\n\n    Returns:\n        str: A message indicating whether the directory was created or already exists.\n    \"\"\"\n    if not os.path.exists(directory_path):\n        os.makedirs(directory_path)  # Create the folder\n        return f\"Folder '{directory_path}' created.\"\n    else:\n        return f\"Folder '{directory_path}' already exists.\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_folder_path = \"/kaggle/working/ComfyUI/models/ipadapter\"\nensure_directory_exists(model_folder_path)\nmodel_name = \"ip-adapter-plus_sdxl_vit-h.safetensors\"\n\nmodel_path = os.path.join(model_folder_path, model_name)\nmodel_url = \"https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus_sdxl_vit-h.safetensors\"\n\n!wget -O $model_path $model_url","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_folder_path = \"/kaggle/working/ComfyUI/models/clip_vision\"\nensure_directory_exists(model_folder_path)\nmodel_name = \"CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\"\n\nmodel_path = os.path.join(model_folder_path, model_name)\nmodel_url = \"https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/resolve/main/model.safetensors\"\n\n!wget -O $model_path $model_url","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_folder_path = \"/kaggle/working/ComfyUI/models/mediapipe\"\nensure_directory_exists(model_folder_path)\nmodel_name = \"selfie_multiclass_256x256.tflite\"\n\nmodel_path = os.path.join(model_folder_path, model_name)\nmodel_url = \"https://storage.googleapis.com/mediapipe-models/image_segmenter/selfie_multiclass_256x256/float32/latest/selfie_multiclass_256x256.tflite\"\n\n!wget -O $model_path $model_url","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install a Eyeful checkpoints in permanent storage\n\nplace = \"/kaggle/working/ComfyUI/models/yolov8\"\nmessage = ensure_directory_exists(place)\nprint(message)\n\nmodel_version_id = 582143\nmodel_name=\"eyefulRobustEyeDetection_v2Paired.zip\"\n\ninstall_civitai_model(api_key=api_key, model_version_id=model_version_id, \n                       place=place, model_name=model_name)\n\n!unzip eyefulRobustEyeDetection_v2Paired.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install a Foocus Inpaint model in permanent storage\n\nmodel_folder_path = \"/kaggle/working/ComfyUI/models/inpaint\"\nensure_directory_exists(model_folder_path)\n\nmodel_name = \"fooocus_inpaint_head.pth\"\nmodel_path = os.path.join(model_folder_path, model_name)\nmodel_url = \"https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/fooocus_inpaint_head.pth\"\n!wget -O $model_path $model_url\n\nmodel_name = \"inpaint_v26.fooocus.patch\"\nmodel_path = os.path.join(model_folder_path, model_name)\nmodel_url = \"https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/inpaint_v26.fooocus.patch\"\n!wget -O $model_path $model_url","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Install a controlnet model in permanent storage\n\n# model_folder_path = \"/kaggle/working/ComfyUI/models/controlnet\"\n# ensure_directory_exists(model_folder_path)\n# model_folder_path = \"/kaggle/working/ComfyUI/models/controlnet/SDXL\"\n# ensure_directory_exists(model_folder_path)\n# model_folder_path = \"/kaggle/working/ComfyUI/models/controlnet/SDXL/controlnet-union-sdxl-1.0\"\n# ensure_directory_exists(model_folder_path)\n\n# model_name = \"diffusion_pytorch_model_promax.safetensors\"\n# model_path = os.path.join(model_folder_path, model_name)\n# model_url = \"https://huggingface.co/xinsir/controlnet-union-sdxl-1.0/resolve/main/diffusion_pytorch_model_promax.safetensors\"\n# !wget -O $model_path $model_url","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install a model in permanent storage\n# Make sure Persistence is set to \"Files only\" or \"Variables and Files\"\n\ncheckpoints =  '/kaggle/working/ComfyUI/models/checkpoints'\n\n# model_name = 'Juggernaut XL inpainting.safetensors'\n# model_version_id = 456538\n# install_civitai_model(api_key=api_key, model_version_id=model_version_id, \n#                       place=checkpoints, model_name=model_name)\n\n# model_name = 'Juggernaut XL.safetensors'\n# model_version_id = 782002\n# install_civitai_model(api_key=api_key, model_version_id=model_version_id, \n#                       place=checkpoints, model_name=model_name)\n\nmodel_name = 'Realism Engine SDXL.safetensors'\nmodel_version_id = 293240\ninstall_civitai_model(api_key=api_key, model_version_id=model_version_id, \n                      place=checkpoints, model_name=model_name)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %rm \"/kaggle/working/ComfyUI/models/checkpoints/Juggernaut XL.safetensors\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Install a LoRA in permanent storage\n# place = 'kaggle/working/ComfyUI/models/loras'\n# model_name = 'DreamArt.safetensors'\n# model_version_id = 137124\n# type=\"Model\"\n# format=\"SafeTensor\"\n\n# install_civitai_model(api_key=api_key, model_version_id=model_version_id, \n#                       place=place, model_name=model_name,\n#                      type=type, format=format)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##Install a model in temporary storage\n# model_url = 'https://civitai.com/api/download/models/160191?type=Model&format=SafeTensor&size=full&fp=fp16'\n# model_name = 'YamersRealism.safetensors'\n# model_url = 'https://civitai.com/api/download/models/456751'\n# model_name = 'HelloWorld-XL.safetensors' \n\n# %cd $temp_models\n# get_ipython().system(f'wget -O \"{model_name}\" \"{model_url}\"')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"--- \n# WebUI","metadata":{}},{"cell_type":"markdown","source":"## Start the WebUI with Pinggy\n* Wait for the GUI to start.  \n* Click the link that ends with .pinggy.link ğŸ˜\n* If generation is still running after the link expires in an hour, wait for the generation to complete and restart the WebUI code block to get a new link","metadata":{}},{"cell_type":"code","source":"# Starting the Web UI with pinggy\n\nfrom multiprocessing import Process\nimport sys\nimport time\n\n!touch log.txt\nopen('log.txt', 'w').close()\n\ndef run_app():\n    cmd = f\"python /kaggle/working/ComfyUI/main.py --force-fp16 & ssh -o StrictHostKeyChecking=no -p 80 -R0:localhost:8188 a.pinggy.io > log.txt\"\n    get_ipython().system(cmd)\n    \ndef print_url():\n    print(\"waiting for output\")\n    time.sleep(2)\n    sys.stdout.flush()\n    \n    found = False\n    with open('log.txt', 'r') as file:\n        end_word = '.pinggy.link'\n        for line in file:\n            start_index = line.find(\"http:\")\n            if start_index != -1:\n                end_index = line.find(end_word, start_index)\n                if end_index != -1:\n                    print(\"ğŸ˜ ğŸ˜ ğŸ˜\")\n                    print(\"URL: \" + line[start_index:end_index + len(end_word)])\n                    print(\"ğŸ˜ ğŸ˜ ğŸ˜\")\n                    found = True\n    if not found:\n        print_url()\n    else:\n        with open('log.txt', 'r') as file:\n            for line in file:\n                print(line)\n    \np_app = Process(target=run_app)\np_url = Process(target=print_url)\np_app.start()\np_url.start()\np_app.join()\np_url.join()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:36:36.035942Z","iopub.execute_input":"2024-12-25T08:36:36.036916Z","iopub.status.idle":"2024-12-25T08:40:48.764974Z","shell.execute_reply.started":"2024-12-25T08:36:36.036881Z","shell.execute_reply":"2024-12-25T08:40:48.763640Z"}},"outputs":[{"name":"stdout","text":"waiting for output\n[START] Security scan\nwaiting for output\nAllocated port 3 for remote forward to localhost:8188\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2024-12-25 08:36:39.762824\n** Platform: Linux\n** Python version: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n** Python executable: /opt/conda/bin/python\n** ComfyUI Path: /kaggle/working/ComfyUI\n** Log path: /kaggle/working/ComfyUI/custom_nodes/comfyui.log\nğŸ˜ ğŸ˜ ğŸ˜\nURL: http://rnqnm-35-244-103-46.a.free.pinggy.link\nğŸ˜ ğŸ˜ ğŸ˜\n\u001b[?1000l\u001b[?1002l\u001b[?1003l\u001b[?1006l\u001b[?2004l\u001b7\u001b[?47h\u001b[?1h\u001b=\u001b)0\u001b[H\u001b[2J\u001b[25;81H\u001b[1;1H\u001b[m\u001b]8;;\u001b\\                                                                                \u001b[2;1H                                                                                \u001b[3;1H                                                                                \u001b[4;1H                                                                                \u001b[5;1H                                                                                \u001b[6;1H                                                                                \u001b[7;1H                                                                                \u001b[8;1H                                                                                \u001b[9;1H                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         \u001b[10;1H                         â”‚                            â”‚                         \u001b[11;1H                         â”‚ Wait while we prepare the  â”‚                         \u001b[12;1H                         â”‚             UI             â”‚                         \u001b[13;1H                         â”‚                            â”‚                         \u001b[14;1H                         â”‚                            â”‚                         \u001b[15;1H                         â”‚                            â”‚                         \u001b[16;1H                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         \u001b[17;1H                                                                                \u001b[18;1H                                                                                \u001b[19;1H                                                                                \u001b[20;1H                                                                                \u001b[21;1H                                                                                \u001b[22;1H                                                                                \u001b[23;1H                                                                                \u001b[24;1H                                                                                \u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[1;28H\u001b[m\u001b]8;;\u001b\\You\u001b[1;32Hare\u001b[1;36Hnot\u001b[1;40Hauthenticated.\u001b[2;1HYour\u001b[2;6Htunnel\u001b[2;13Hwill\u001b[2;18Hexpire\u001b[2;25Hin\u001b[2;28H60\u001b[2;31Hminutes.\u001b[2;40HUpgrade\u001b[2;48Hto\u001b[2;51HPinggy\u001b[2;58HPro\u001b[2;62Hto\u001b[2;65Hget\u001b[2;69Hunrestricted\u001b[3;23Htunnels.\u001b[3;32Hhttps://dashboard.pinggy.io\u001b[5;4Hhttp://rnqnm-35-244-103-46.a.free.pinggy.link\u001b[6;4Hhttps://rnqnm-35-244-103-46.a.free.pinggy.link\u001b[9;26H                              \u001b[10;26H \u001b[10;55H \u001b[11;26H \u001b[11;28H    \u001b[11;33H     \u001b[11;39H  \u001b[11;42H       \u001b[11;50H   \u001b[11;55H \u001b[12;26H \u001b[12;40H  \u001b[12;55H \u001b[13;26H \u001b[13;55H \u001b[14;26H \u001b[14;55H \u001b[15;26H \u001b[15;55H \u001b[16;26H                              \u001b[24;28HPress\u001b[24;34H`h`\u001b[24;38Hfor\u001b[24;42Hkeybindings\u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[25;81H\u001b[m\u001b]8;;\u001b\\\u001b[H\u001b[2J\u001b[1;28H\u001b[m\u001b]8;;\u001b\\You\u001b[1;32Hare\u001b[1;36Hnot\u001b[1;40Hauthenticated.\u001b[2;1HYour\u001b[2;6Htunnel\u001b[2;13Hwill\u001b[2;18Hexpire\u001b[2;25Hin\u001b[2;28H60\u001b[2;31Hminutes.\u001b[2;40HUpgrade\u001b[2;48Hto\u001b[2;51HPinggy\u001b[2;58HPro\u001b[2;62Hto\u001b[2;65Hget\u001b[2;69Hunrestricted\u001b[3;23Htunnels.\u001b[3;32Hhttps://dashboard.pinggy.io\u001b[5;4Hhttp://rnqnm-35-244-103-46.a.free.pinggy.link\u001b[6;4Hhttps://rnqnm-35-244-103-46.a.free.pinggy.link\u001b[24;28HPress\u001b[24;34H`h`\u001b[24;38Hfor\u001b[24;42Hkeybindings\u001b[25;81H\n\nPrestartup times for custom nodes:\n   4.3 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n\nTotal VRAM 16269 MB, total RAM 32103 MB\npytorch version: 2.0.0\nForcing FP16.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla P100-PCIE-16GB : cudaMallocAsync\nUsing pytorch attention\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[Prompt Server] web root: /kaggle/working/ComfyUI/web\n\u001b[94mtheUpsiders Logic Nodes: \u001b[92mLoaded\u001b[0m\n/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n  warnings.warn(_BETA_TRANSFORMS_WARNING)\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n  warnings.warn(_BETA_TRANSFORMS_WARNING)\nAdding /kaggle/working/ComfyUI/custom_nodes to sys.path\nCould not find efficiency nodes\nCould not find ControlNetPreprocessors nodes\nCould not find AdvancedControlNet nodes\nCould not find AnimateDiff nodes\nLoaded IPAdapter nodes from /kaggle/working/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\nCould not find VideoHelperSuite nodes\nCould not load ImpactPack nodes Could not find ImpactPack nodes\n## lama model not found: /kaggle/working/ComfyUI/models/lama/big-lama.pt, pls download from https://github.com/enesmsahin/simple-lama-inpainting/releases/download/v0.1.0/big-lama.pt\nconnect_to localhost port 8188: failed.\nNumExpr defaulting to 4 threads.\n2024-12-25 08:36:49.974044 /kaggle/working/ComfyUI/custom_nodes\n2024-12-25 08:36:49.974179 ############################################\n2024-12-25 08:36:49.974245 /kaggle/working/ComfyUI/custom_nodes/custom_nodes/ComfyUI-NAI-styler/CSV\n2024-12-25 08:36:49.974326 ############################################\n2024-12-25 08:36:49.974675 []\n2024-12-25 08:36:49.974795 ############################################\nRequirement already satisfied: ultralytics in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (8.3.54)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.24.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.0.0)\n\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n\u001b[0m2024-12-25 08:36:50.938394 ### Loading: ComfyUI-Manager (V2.55.5)\n2024-12-25 08:36:50.998483 ### ComfyUI Version: v0.3.9-22-g99a1fb6 | Released on '2024-12-24'\n\nImport times for custom nodes:\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/websocket_image_save.py\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/Comfyui-Simple-Json-Node\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Logic\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Universal-Styler\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/comfyui-inpaint-nodes\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI_essentials\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n   0.0 seconds: /kaggle/working/ComfyUI/custom_nodes/comfyui-easyapi-nodes\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager\n   0.1 seconds: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Yolo-Cropper\n   0.5 seconds: /kaggle/working/ComfyUI/custom_nodes/comfyui-art-venture\n   1.0 seconds: /kaggle/working/ComfyUI/custom_nodes/Comfyui-Yolov8-JSON\n   3.7 seconds: /kaggle/working/ComfyUI/custom_nodes/a-person-mask-generator\n\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\n2024-12-25 08:36:51.072227 [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n2024-12-25 08:36:51.226961 [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n2024-12-25 08:36:51.236058 [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n2024-12-25 08:36:51.254878 [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n2024-12-25 08:36:51.283119 [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n2024-12-25 08:37:15.167081 FETCH DATA from: /kaggle/working/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n2024-12-25 08:37:16.286229 Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press \"Refresh\".\n                  Your current root directory is: /kaggle/working/ComfyUI\n            \n2024-12-25 08:37:16.286411 Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press \"Refresh\".\n                  Your current root directory is: /kaggle/working/ComfyUI\n            \n2024-12-25 08:37:16.286525 Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press \"Refresh\".\n                  Your current root directory is: /kaggle/working/ComfyUI\n            \n2024-12-25 08:37:16.286630 Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press \"Refresh\".\n                  Your current root directory is: /kaggle/working/ComfyUI\n            \n2024-12-25 08:37:16.286736 Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press \"Refresh\".\n                  Your current root directory is: /kaggle/working/ComfyUI\n            \n2024-12-25 08:37:16.286819 Error. No naistyles.csv found. Put your naistyles.csv in the custom_nodes/ComfyUI_NAI-mod/CSV directory of ComfyUI. Then press \"Refresh\".\n                  Your current root directory is: /kaggle/working/ComfyUI\n            \ngot prompt\nFailed to validate prompt for output 105:\n* LoadImage 6:\n  - Custom validation failed for node: image - Invalid image file: IMG_2242.jpg\n* LoadImage 7:\n  - Custom validation failed for node: image - Invalid image file: att.ihLOjgpxv-LlqO81w3gKEPGAGqoA_hPoRQG7oxsehI4.png\nOutput will be ignored\nFailed to validate prompt for output 104:\nOutput will be ignored\nFailed to validate prompt for output 51:\nOutput will be ignored\nFailed to validate prompt for output 91:\nOutput will be ignored\nFailed to validate prompt for output 21:\nOutput will be ignored\nFailed to validate prompt for output 159:\nOutput will be ignored\nFailed to validate prompt for output 77:\nOutput will be ignored\nFailed to validate prompt for output 50:\nOutput will be ignored\nFailed to validate prompt for output 202:\nOutput will be ignored\nFailed to validate prompt for output 293:\nOutput will be ignored\nFailed to validate prompt for output 28:\nOutput will be ignored\nFailed to validate prompt for output 113:\nOutput will be ignored\nFailed to validate prompt for output 296:\nOutput will be ignored\nFailed to validate prompt for output 31:\nOutput will be ignored\nFailed to validate prompt for output 182:\nOutput will be ignored\nFailed to validate prompt for output 87:\nOutput will be ignored\nFailed to validate prompt for output 18:\nOutput will be ignored\nFailed to validate prompt for output 118:\nOutput will be ignored\nFailed to validate prompt for output 58:\nOutput will be ignored\nFailed to validate prompt for output 209:\nOutput will be ignored\nFailed to validate prompt for output 178:\nOutput will be ignored\nFailed to validate prompt for output 271:\nOutput will be ignored\nFailed to validate prompt for output 65:\nOutput will be ignored\nFailed to validate prompt for output 14:\nOutput will be ignored\nFailed to validate prompt for output 33:\nOutput will be ignored\nFailed to validate prompt for output 89:\nOutput will be ignored\nFailed to validate prompt for output 139:\nOutput will be ignored\nFailed to validate prompt for output 5:\nOutput will be ignored\nFailed to validate prompt for output 43:\nOutput will be ignored\nFailed to validate prompt for output 26:\nOutput will be ignored\nFailed to validate prompt for output 168:\nOutput will be ignored\nFailed to validate prompt for output 205:\nOutput will be ignored\nFailed to validate prompt for output 24:\nOutput will be ignored\nFailed to validate prompt for output 304:\nOutput will be ignored\nFailed to validate prompt for output 42:\nOutput will be ignored\nFailed to validate prompt for output 59:\nOutput will be ignored\nFailed to validate prompt for output 80:\nOutput will be ignored\nFailed to validate prompt for output 11:\nOutput will be ignored\nFailed to validate prompt for output 213:\nOutput will be ignored\nFailed to validate prompt for output 221:\nOutput will be ignored\nFailed to validate prompt for output 152:\nOutput will be ignored\nFailed to validate prompt for output 112:\nOutput will be ignored\nFailed to validate prompt for output 260:\nOutput will be ignored\nFailed to validate prompt for output 179:\nOutput will be ignored\nFailed to validate prompt for output 4:\nOutput will be ignored\nFailed to validate prompt for output 215:\nOutput will be ignored\nFailed to validate prompt for output 68:\nOutput will be ignored\nFailed to validate prompt for output 35:\nOutput will be ignored\ninvalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\ngot prompt\nFailed to validate prompt for output 105:\n* LoadImage 6:\n  - Custom validation failed for node: image - Invalid image file: IMG_2242.jpg\nOutput will be ignored\nFailed to validate prompt for output 104:\nOutput will be ignored\nFailed to validate prompt for output 51:\nOutput will be ignored\nFailed to validate prompt for output 91:\nOutput will be ignored\nFailed to validate prompt for output 21:\nOutput will be ignored\nFailed to validate prompt for output 159:\nOutput will be ignored\nFailed to validate prompt for output 77:\nOutput will be ignored\nFailed to validate prompt for output 113:\nOutput will be ignored\nFailed to validate prompt for output 296:\nOutput will be ignored\nFailed to validate prompt for output 182:\nOutput will be ignored\nFailed to validate prompt for output 18:\nOutput will be ignored\nFailed to validate prompt for output 118:\nOutput will be ignored\nFailed to validate prompt for output 178:\nOutput will be ignored\nFailed to validate prompt for output 271:\nOutput will be ignored\nFailed to validate prompt for output 65:\nOutput will be ignored\nFailed to validate prompt for output 33:\nOutput will be ignored\nFailed to validate prompt for output 89:\nOutput will be ignored\nFailed to validate prompt for output 5:\nOutput will be ignored\nFailed to validate prompt for output 43:\nOutput will be ignored\nFailed to validate prompt for output 168:\nOutput will be ignored\nFailed to validate prompt for output 24:\nOutput will be ignored\nFailed to validate prompt for output 59:\nOutput will be ignored\nFailed to validate prompt for output 80:\nOutput will be ignored\nFailed to validate prompt for output 213:\nOutput will be ignored\nFailed to validate prompt for output 221:\nOutput will be ignored\nFailed to validate prompt for output 152:\nOutput will be ignored\nFailed to validate prompt for output 112:\nOutput will be ignored\nFailed to validate prompt for output 179:\nOutput will be ignored\nFailed to validate prompt for output 215:\nOutput will be ignored\nFailed to validate prompt for output 68:\nOutput will be ignored\nFailed to validate prompt for output 35:\nOutput will be ignored\nWARNING: name 'hashlib' is not defined\nWARNING: [Errno 2] No such file or directory: '/kaggle/working/ComfyUI/input/IMG_2242.jpg'\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1735115878.223667    3283 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nW0000 00:00:1735115878.287020    3322 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n2024-12-25 08:37:58.287701 /opt/conda/lib/python3.10/site-packages/mediapipe/tasks/python/vision/image_segmenter.py:158: UserWarning: MessageFactory class is deprecated. Please use GetMessageClass() instead of MessageFactory.GetPrototype. MessageFactory class will be removed after 2024.\n  graph_config = self._runner.get_graph_config()\n2024-12-25 08:37:58.570844 downloading https://huggingface.co/Bingsu/adetailer/resolve/main/face_yolov8n.pt?download=true to /kaggle/working/ComfyUI/models/yolov8/face_yolov8n.pt\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 10.7MiB/s]\n\n2024-12-25 08:38:00.119521 0: 640x640 1 face, 6.0ms\nSpeed: 6.5ms preprocess, 6.0ms inference, 109.5ms postprocess per image at shape (1, 3, 640, 640)\n\n2024-12-25 08:38:00.435189 0: 640x640 1 eyes, 7.9ms\nSpeed: 3.0ms preprocess, 7.9ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\nI0000 00:00:1735115880.731933    3283 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\nW0000 00:00:1735115880.796281    3352 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nI0000 00:00:1735115881.179862    3283 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\nW0000 00:00:1735115881.243373    3360 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nI0000 00:00:1735115881.999700    3283 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\nW0000 00:00:1735115882.061692    3369 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nPrompt executed in 5.35 seconds\ngot prompt\nWARNING: name 'hashlib' is not defined\n\n2024-12-25 08:38:25.119128 0: 640x640 1 eyes, 7.9ms\nSpeed: 2.9ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nmodel weight dtype torch.float16, manual cast: None\nmodel_type EPS\nUsing pytorch attention in VAE\nUsing pytorch attention in VAE\nRequested to load SDXLClipModel\nloaded completely 9.5367431640625e+25 1560.802734375 True\nI0000 00:00:1735115909.981943    3283 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\nW0000 00:00:1735115910.028958    3393 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n2024-12-25 08:38:30.030044 /opt/conda/lib/python3.10/site-packages/mediapipe/tasks/python/vision/image_segmenter.py:158: UserWarning: MessageFactory class is deprecated. Please use GetMessageClass() instead of MessageFactory.GetPrototype. MessageFactory class will be removed after 2024.\n  graph_config = self._runner.get_graph_config()\n\n2024-12-25 08:38:32.205317 0: 640x480 1 face, 52.0ms\nSpeed: 2.5ms preprocess, 52.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n\n2024-12-25 08:38:32.511563 0: 640x512 1 eyes, 57.0ms\nSpeed: 2.6ms preprocess, 57.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\nI0000 00:00:1735115912.825347    3283 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\nW0000 00:00:1735115912.871401    3409 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nI0000 00:00:1735115913.389511    3283 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\nW0000 00:00:1735115913.435589    3416 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nToken indices sequence length is longer than the specified maximum sequence length for this model (128 > 77). Running this sequence through the model will result in indexing errors\nToken indices sequence length is longer than the specified maximum sequence length for this model (128 > 77). Running this sequence through the model will result in indexing errors\nRequested to load AutoencoderKL\nloaded completely 9.5367431640625e+25 319.11416244506836 True\nI0000 00:00:1735115918.055465    3283 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:77) display != EGL_NO_DISPLAYeglGetDisplay() returned error 0x300c\nW0000 00:00:1735115918.103551    3433 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n  warnings.warn(\nRequested to load CLIPVisionModelProjection\nloaded completely 9.5367431640625e+25 1208.09814453125 True\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nWarning torch.load doesn't support weights_only on this pytorch version, loading unsafely.\n[comfyui-inpaint-nodes] Injecting patched comfy.model_patcher.ModelPatcher.calculate_weight\nRequested to load SDXL\nloaded completely 9.5367431640625e+25 4897.0483474731445 True\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:13<00:00,  2.95s/it]\nPrompt executed in 101.35 seconds\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m p_app\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     41\u001b[0m p_url\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 42\u001b[0m \u001b[43mp_app\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m p_url\u001b[38;5;241m.\u001b[39mjoin()\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"},{"name":"stdout","text":"Connection to a.pinggy.io closed by remote host.\nConnection to a.pinggy.io closed.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Workflow to Code","metadata":{}},{"cell_type":"markdown","source":"## Install","metadata":{}},{"cell_type":"code","source":"# %cd /kaggle/working/ComfyUI/custom_nodes\n# !git clone https://github.com/atmaranto/ComfyUI-SaveAsScript.git\n# %cd ComfyUI-SaveAsScript\n# !pip install -r requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %cd /kaggle/working/ComfyUI/custom_nodes\n# !git clone https://github.com/pydn/ComfyUI-to-Python-Extension.git\n# %cd ComfyUI-to-Python-Extension\n# !pip install -r requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %cd /kaggle/working/ComfyUI/custom_nodes/ComfyUI-to-Python-Extension\n# !python comfyui_to_python.py -h","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %cd /kaggle/working/ComfyUI/custom_nodes/ComfyUI-to-Python-Extension\n# !python comfyui_to_python.py \\\n# -f \"/kaggle/input/virtual-tryon-workflow/Virtual_TryOn_api(1).json\" \\\n# -o \"/kaggle/working/ComfyUI/workflow.py\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %cd /kaggle/working/ComfyUI/custom_nodes/ComfyUI-SaveAsScript\n# !python comfyui_to_python.py \\\n# \"/kaggle/input/virtual-tryon-workflow/Virtual_TryOn_api(1).json\" \\\n# --output \"/kaggle/working/ComfyUI/workflow.py\" -y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !python \"/kaggle/working/ComfyUI/workflow.py\" -h","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Run","metadata":{}},{"cell_type":"code","source":"# !python /kaggle/working/ComfyUI/workflow.py \\\n# \"/kaggle/working/Images/Taylor_Swift_at_the_Golden_Globes_2024_(Enhanced,_cropped)_1.jpg\" \\\n# \"/kaggle/working/Images/30577753.jpeg.png\" --queue-size 1 --","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n---\n# File Browser","metadata":{}},{"cell_type":"markdown","source":"##  Install FileBrowser","metadata":{}},{"cell_type":"code","source":"%cd /kaggle\n!wget https://github.com/filebrowser/filebrowser/releases/download/v2.27.0/linux-amd64-filebrowser.tar.gz\n!tar xvfz linux-amd64-filebrowser.tar.gz\n!chmod a+x /kaggle/filebrowser\n!/kaggle/filebrowser config init \n!/kaggle/filebrowser config set --auth.method=noauth > /dev/null\n!/kaggle/filebrowser config set --branding.theme=dark > /dev/null\n!/kaggle/filebrowser users add admin admin \n!/kaggle/filebrowser config export \"/kaggle/config.json\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Run FileBrowser","metadata":{}},{"cell_type":"code","source":"%cd /kaggle\n        \nfrom multiprocessing import Process\nimport sys\nimport time\n\n!touch log.txt\nopen('log.txt', 'w').close()\n\ndef run_app():\n    !/kaggle/filebrowser -c \"/kaggle/config.json\" & ssh -o StrictHostKeyChecking=no -p 80 -R0:localhost:8080 a.pinggy.io > log.txt > log.txt\n    \ndef print_url():\n    print(\"waiting for output\")\n    time.sleep(2)\n    sys.stdout.flush()\n    \n    found = False\n    with open('log.txt', 'r') as file:\n        end_word = '.pinggy.link'\n        for line in file:\n            start_index = line.find(\"http:\")\n            if start_index != -1:\n                end_index = line.find(end_word, start_index)\n                if end_index != -1:\n                    print(\"ğŸ˜ ğŸ˜ ğŸ˜\")\n                    print(\"URL: \" + line[start_index:end_index + len(end_word)])\n                    print(\"ğŸ˜ ğŸ˜ ğŸ˜\")\n                    found = True\n    if not found:\n        print_url()\n    else:\n        with open('log.txt', 'r') as file:\n            for line in file:\n                print(line)\n    \np_app = Process(target=run_app)\np_url = Process(target=print_url)\np_app.start()\np_url.start()\np_app.join()\np_url.join()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}